<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: SQL | Traversing the Internets]]></title>
  <link href="http://samueldowens.github.io/blog/categories/sql/atom.xml" rel="self"/>
  <link href="http://samueldowens.github.io/"/>
  <updated>2013-10-15T10:29:06-04:00</updated>
  <id>http://samueldowens.github.io/</id>
  <author>
    <name><![CDATA[Samuel Owens]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Flatiron School Day Twenty-Two - SQL Bits]]></title>
    <link href="http://samueldowens.github.io/blog/2013/10/15/flatiron-school-day-twenty-two-sql-bits/"/>
    <updated>2013-10-15T08:34:00-04:00</updated>
    <id>http://samueldowens.github.io/blog/2013/10/15/flatiron-school-day-twenty-two-sql-bits</id>
    <content type="html"><![CDATA[<p>I started working on a <a href="https://github.com/samueldowens/hacker_news_scraper" target="_blank">mini-project</a> yesterday bto reinforce the different topics we&rsquo;re covering in Flatiron. While it&rsquo;s not done-enough to go over in detail yet I wanted to cover a few bits of SQL that I found particularly useful in getting the program to its current state.</p>

<p>The SQL side of the program exists to keep a unique record of articles off of Hacker News that meet certain criteria. The scrape can be run multiple times over multiple days, weeks, etc. so it was important that the SQL side of the program not continuously re-enter the same article over multiple scrapes. Here&rsquo;s what the code looks like&hellip;</p>

<p>```ruby database.rb
class Database</p>

<p>  @@db = SQLite3::Database.new(&lsquo;articles.db&rsquo;)
  @@db.execute(&ldquo;CREATE TABLE if NOT EXISTS articles(id INTEGER PRIMARY KEY ASC, title TEXT UNIQUE, url TEXT, parent_url TEXT, points INTEGER);&rdquo;)</p>

<p>  def self.insert(array)</p>

<pre><code>array.each do |article|
  sql = "REPLACE INTO articles(title, url, parent_url, points) VALUES (?,?,?,?)"
  @@db.execute(sql, article.title, article.url, article.parent_url, article.points)
end
</code></pre>

<p>  end</p>

<p>end
```</p>

<p>There are a few bits of this code I would like to highlight.</p>

<p>&ldquo;CREATE TABLE if NOT EXISTS&rdquo; &ndash; This one should be familiar to most Flatiron students already, but since some of our projects and examples have assumed the existance of a table I thought it would be worth mentioning. The &lsquo;if NOT EXISTS&rsquo; part is important to make sure that you are not creating a new table every time the code runs, this code will only execute the first time the program runs, unless the &lsquo;articles&rsquo; table is deleted from the database (this would have to be done manually by the user).</p>

<p>&ldquo;title TEXT UNIQUE&rdquo; &ndash; This is one that I had to look up what I wanted SQL to do before I could figure out how to do it. This tells the database that while the &lsquo;title&rsquo; column is not the primary key, that it is unique and that SQL should raise an error if something attempts to add an item with the same title as something else to the table.</p>

<p>&ldquo;REPLACE INTO&rdquo; &ndash; The work-horse piece of code, normally we would use &lsquo;INSERT INTO&rsquo; but in this case, I chose to use &lsquo;REPLACE&rsquo; for two reasons. First, it resolves any conflicting titles by replacing the old entry with the newer one, which makes sure that we only have unique entries in the table. Second since it replaces the old version with the new one, it will update any other data about the article that has changed since the last time the scrape was run (for instance, if the number of points were to change).</p>

<p>These three peices that were previously unfamiliar to me do a lot of work in very little space. Because I don&rsquo;t need to write methods to check for some of the things these take care of automatically, we save a lot of space and the code is easy to read. Thanks for reading, I hope if you&rsquo;re working with SQL these little bits are helpful!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Flatiron School Day Weekend Two]]></title>
    <link href="http://samueldowens.github.io/blog/2013/10/07/flatiron-school-weekend-two/"/>
    <updated>2013-10-07T08:38:00-04:00</updated>
    <id>http://samueldowens.github.io/blog/2013/10/07/flatiron-school-weekend-two</id>
    <content type="html"><![CDATA[<p>Weekend two was a lot of fun. I managed to end up pretty comfortable with SQL pretty early in the day and we moved onto some other new and interesting things later.</p>

<p>Namely Nokogiri, this ruby gem for scraping web pages was the big learning focus of my weekend. Our project was to use Nokogiri to scrape the Flatiron student webpage for information on each student and export that data into an SQL database. It took a lot of trial and error playing around with Nokogiri before we figured things out, but by the end my whole group was pretty comfortable navigating the trees of data that is HTML.</p>

<p>We also had to redo the quiz from week one but make it object oriented, having to have classes in each of the previous tests. I thought the difficulty on that assignment was pretty easy but that it was useful in providing repetition in looking at grouping things as a class.</p>

<p>Lastly we were given an assignment called playlister, which was a multi-file, multi-class assignment that had a suite of rspec tests that needed to be passed. I sure hope this was the stretch assignment for the weekend as I spent a lot of time struggling with it.</p>

<p>I&rsquo;m really looking forward to week three. After two weeks I&rsquo;m already amazed at the tools we&rsquo;re beginning to scratch the surface of using. I can&rsquo;t imagine after 10 more weeks how many cool things we&rsquo;ll be able to build. I feel like a child who just learned what a car can do but whose feet can&rsquo;t yet reach the pedals. Once they can it&rsquo;s going to be a fun time!</p>
]]></content>
  </entry>
  
</feed>
